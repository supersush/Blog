---
layout: post
title: "图卷积神经网络"
author: "sush"
header-img: "img/post-bg-web.jpg"
header-mask: 0.4
tags:
  - GCN
---
### **GCN学习笔记**
#### **前言** ####
CNN在计算机视觉上有非常广泛且有效的应用，可以有效的提取空间特征，由于图像是Euclidean Structure的，能够很方便的用卷积核进行卷积操作。  
但是生活中更多的是Non Euclidean Structure的数据，对于这样的数据如何有效的提取其网络拓扑成为了研究的重点

#### Graph指用顶点和边建立相应关系的拓扑结构 ####
度矩阵D是一个对角矩阵，对角线上元素依次为各个顶点的度  
邻接矩阵A描述的是各个顶点和其他顶点边存在的情况
<img src="/blog/img/in-post/laplacian_matrix.png">

#### 三种拉普拉斯矩阵 ####
<center>Combinatorial Laplacian</center>
<img src="http://latex.codecogs.com/gif.latex? L=D-A">
<img src="/blog/img/in-post/combinatorial_laplacian.png">


<center>Symmetric normalized Laplacian</center>
<img src="http://latex.codecogs.com/gif.latex? L^{sym}=D^{-\frac{1}{2}}">
<img src="/blog/img/in-post/sym.png">

<center>Random walk normalized Laplacian</center>
<img src="http://latex.codecogs.com/gif.latex? L^{sym}=D^{-\frac{1}{2}}LD^{-\frac{1}{2}}=I-D^{-\frac{1}{2}}AD^{-\frac{1}{2}}">
<img src="/blog/img/in-post/rwnl.png">

##### 拉普拉斯矩阵性质 #####
(1)拉普拉斯矩阵是对称矩阵，可以进行特征分解(谱分解)
(2)拉普拉斯矩阵只在中心顶点和一阶相连的顶点上（1-hop neighbor）有非0元素，其余之处均为0

#### 拉普拉斯矩阵谱分解(特征分解) ####
由于拉普拉斯矩阵是实对称矩阵，有以下性质:  
1 对称矩阵一定n个线性无关的特征向量  
2 特征值一定非负  
3 对称矩阵特征向量相互正交  

由于1性质，拉普拉斯矩阵可以进行特征分解（谱分解）
<img src="/blog/img/in-post/spectral_domain.png">

#### 图上的傅里叶变换 ####
图神经网络的核心工作是对空间域(Spatial Domain)中节点的Embedding进行卷积操作(即聚合邻居Embedding信息)，然而图数据和图像数据的差别在于节点邻居个数、次序都是不定的，因此传统用于图像上的CNN模型中的卷积操作(Convolution Operator)不能直接用在图上，因此需要从频谱域(Spectral Domain)上重新定义这样的卷积操作再通过卷积定理转换回空间域上。

为了在频谱域和空间域中转换，我们借助了傅里叶公式，并且定义了图上傅里叶变换(从空间域变换到频谱域)和图上傅里叶逆变换(从频谱域回到空间域)的变换公式。具体操作是我们将节点的Embedding通过傅里叶正变换从空间域变换到了频谱域
，在频谱域上和卷积核进行卷积操作，再将变换后的节点Embedding通过傅里叶逆变换回到空间域，参与后续的分类等任务。  

详情还是参见这篇博客吧，写的很具体
[GNN 教程：漫谈谱图理论和GCN的起源](https://archwalker.github.io/blog/2019/06/16/GNN-Spectral-Graph.html)




